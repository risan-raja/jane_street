sequence_length: 242
prediction_length: 121
activation_fn: relu
num_blocks: 2
dropout_rate: 0.1
input_channels: 9
extra_channels: 79
hidden_channels: 64
static_channels: 4
ff_dim: 64
output_channels: 1
normalize_before: true
norm_type: layer
encoder_length: 242
decoder_length: 121
